{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28dabf6b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-09T10:01:32.061367Z",
     "iopub.status.busy": "2023-10-09T10:01:32.060879Z",
     "iopub.status.idle": "2023-10-09T10:01:32.114358Z",
     "shell.execute_reply": "2023-10-09T10:01:32.113277Z"
    },
    "papermill": {
     "duration": 0.063678,
     "end_time": "2023-10-09T10:01:32.116940",
     "exception": false,
     "start_time": "2023-10-09T10:01:32.053262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README (1).md\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config (1).json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/trainer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_test.sh\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_train.sh\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/trainer_state.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/eval_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/training_args.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/all_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/test_results.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/trainer_state.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/training_args.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scaler.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scheduler.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/special_tokens_map.json\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/optimizer.pt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/rng_state.pth\n",
      "/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/added_tokens.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/rust_model.ot\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.generator.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/generator_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/gitattributes.txt\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/spm.model\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/README.md\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tf_model.h5\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tokenizer_config.json\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/pytorch_model.bin\n",
      "/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/gitattributes.txt\n",
      "/kaggle/input/autocorrect/autocorrect-2.6.1.tar\n",
      "/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\n",
      "/kaggle/input/models-py/content_model.joblib\n",
      "/kaggle/input/models-py/wording_model.joblib\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\n",
      "/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dbe6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:01:32.129090Z",
     "iopub.status.busy": "2023-10-09T10:01:32.128531Z",
     "iopub.status.idle": "2023-10-09T10:01:57.480095Z",
     "shell.execute_reply": "2023-10-09T10:01:57.478993Z"
    },
    "papermill": {
     "duration": 25.360295,
     "end_time": "2023-10-09T10:01:57.482586",
     "exception": false,
     "start_time": "2023-10-09T10:01:32.122291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import torch\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokens import Doc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from string import punctuation as punc\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from textblob import TextBlob\n",
    "import math\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import AutoTokenizer,TFAutoModel, pipeline\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "import textstat\n",
    "\n",
    "\n",
    "\n",
    "class NLTKTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        # Tokenize the text using nltk's word_tokenize\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Convert the list of words to a spaCy Doc object\n",
    "        return Doc(self.vocab, words=words)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# Set spaCy's tokenizer to the custom tokenizer\n",
    "nlp.tokenizer = NLTKTokenizer(nlp.vocab)\n",
    "checker = SpellChecker()\n",
    "speller = Speller(lang='en')\n",
    "english = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e152e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:01:57.495465Z",
     "iopub.status.busy": "2023-10-09T10:01:57.494544Z",
     "iopub.status.idle": "2023-10-09T10:01:57.623911Z",
     "shell.execute_reply": "2023-10-09T10:01:57.622784Z"
    },
    "papermill": {
     "duration": 0.138159,
     "end_time": "2023-10-09T10:01:57.626178",
     "exception": false,
     "start_time": "2023-10-09T10:01:57.488019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "prompt_df = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "test_summary = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "test_prompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8c3a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:01:57.638733Z",
     "iopub.status.busy": "2023-10-09T10:01:57.638356Z",
     "iopub.status.idle": "2023-10-09T10:02:12.930965Z",
     "shell.execute_reply": "2023-10-09T10:02:12.929828Z"
    },
    "papermill": {
     "duration": 15.301574,
     "end_time": "2023-10-09T10:02:12.933493",
     "exception": false,
     "start_time": "2023-10-09T10:01:57.631919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n",
      "- This IS expected if you are initializing TFDebertaV2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDebertaV2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDebertaV2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL_DIR = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(SAVED_MODEL_DIR)\n",
    "model = TFAutoModel.from_pretrained(SAVED_MODEL_DIR,from_pt=True)\n",
    "\n",
    "# fe = pipeline('feature-extraction', tokenizer=tokenizer,model=model,torch_dtype=torch.float16,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf25417e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:02:12.949128Z",
     "iopub.status.busy": "2023-10-09T10:02:12.948746Z",
     "iopub.status.idle": "2023-10-09T10:02:12.999614Z",
     "shell.execute_reply": "2023-10-09T10:02:12.998695Z"
    },
    "papermill": {
     "duration": 0.062718,
     "end_time": "2023-10-09T10:02:13.002008",
     "exception": false,
     "start_time": "2023-10-09T10:02:12.939290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Overlap Score\n",
    "\n",
    "def tree_depth_from_token(token):\n",
    "    \"\"\"Calculate the depth of a subtree rooted at a token.\"\"\"\n",
    "    if not list(token.children):\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + max(tree_depth_from_token(child) for child in token.children)\n",
    "\n",
    "def average_dependency_tree_depth(doc):\n",
    "    \"\"\"Compute the average depth of the dependency tree.\"\"\"\n",
    "    root_tokens = [tok for tok in doc if tok.dep_ == 'ROOT']\n",
    "    if not root_tokens:\n",
    "        return 0\n",
    "    depths = [tree_depth_from_token(token) for token in root_tokens]\n",
    "    return sum(depths) / len(depths)\n",
    "\n",
    "def process_text(doc):\n",
    "    # Using collections.Counter to count the occurrences efficiently\n",
    "    pos_counts = Counter([token.pos_ for token in doc if not token.is_stop])\n",
    "\n",
    "    # Extract counts directly using the dictionary\n",
    "    num_nouns = pos_counts.get(\"NOUN\", 0)\n",
    "    num_verbs = pos_counts.get(\"VERB\", 0)\n",
    "    num_adverbs = pos_counts.get(\"ADV\", 0)\n",
    "    stops = sum(1 for token in doc if token.is_stop)\n",
    "\n",
    "    return stops, num_nouns, num_verbs, num_adverbs\n",
    "\n",
    "\n",
    "def extract_features(row, docs, context_docs):\n",
    "    idx = row.name\n",
    "    doc = docs[idx]\n",
    "    context = context_docs[idx]\n",
    "    \n",
    "    # Word Tokenize\n",
    "    tokens = [tok.text.lower() for tok in doc]\n",
    "    context_tokens = [tok.text.lower() for tok in context]\n",
    "    \n",
    "    # Capital Error\n",
    "    capital_error = sum(1 for sent in doc.sents if not sent.text[0].isupper())\n",
    "    \n",
    "    # 1. Length of the summary\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # 2. Number of unique words\n",
    "    unique_words = len(set(tokens))\n",
    "    \n",
    "    #3. counter\n",
    "    total_tokens = len(tokens) if length > 0 else 1\n",
    "    word_counts = Counter(tokens)\n",
    "    once = sum(1 for word, count in word_counts.items() if count == 1)\n",
    "    twice = sum(1 for word, count in word_counts.items() if count == 2)\n",
    "    \n",
    "    # 4. Named entities\n",
    "    entities = set(ent.text.lower() for ent in doc.ents)\n",
    "    context_entities = set(ent.text.lower() for ent in context.ents)\n",
    "    num_entities = len(entities)\n",
    "    context_num_entities = len(context_entities)\n",
    "    \n",
    "    # Calculate the overlap between the two sets\n",
    "    overlap_entities = context_entities.intersection(entities)\n",
    "    \n",
    "    # Calculate the coverage score: (number of overlapping entities) / (number of entities in original text)\n",
    "    coverage_score = len(overlap_entities) / len(context_entities) if len(context_entities) > 0 else 0\n",
    "    num_overlap_entities = len(overlap_entities)\n",
    "    \n",
    "    named_entity_ratio = float(num_entities/total_tokens)\n",
    "    context_entity_ratio = float(context_num_entities/len(context_tokens))\n",
    "    \n",
    "    # 5. Average word length\n",
    "    avg_word_len = round(sum([len(token) for token in tokens])/total_tokens, ndigits=4)\n",
    "    context_avg_word_len = round(sum([len(token) for token in context_tokens])/len(context_tokens), ndigits=4)\n",
    "    \n",
    "    # 6. Summary Polarity\n",
    "    text_blob = TextBlob(row['text'])\n",
    "    context_blob = TextBlob(row['prompt_text'])\n",
    "    sentiment_polarity = text_blob.sentiment.polarity\n",
    "    subjectivity = text_blob.subjectivity\n",
    "    context_subjectivity = context_blob.subjectivity\n",
    "    context_polarity = context_blob.sentiment.polarity\n",
    "    error = sum(1 for token in tokens if token not in english)\n",
    "    error_ratio = error/total_tokens\n",
    "    \n",
    "    \n",
    "    # 7. Stopwords verbs and nouns\n",
    "    stops,num_nouns, num_verbs, num_adverbs = process_text(doc)\n",
    "    context_stops,context_nouns, context_verbs, context_adverbs = process_text(context)\n",
    "    \n",
    "    # 8. Numerical entities\n",
    "    num_numerical_entities = len([ent for ent in doc.ents if ent.label_ == \"CARDINAL\"])\n",
    "    \n",
    "    \n",
    "    # 9. Sentece count\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    sentence = len(sentences) if len(sentences) > 0 else 1\n",
    "    avg_sentence = float(sentence / total_tokens)\n",
    "    avg_unique_sentence = float(sentence /unique_words) if unique_words > 0 else 0.0\n",
    "    \n",
    "    avg_sentence_length = sum(len(sent) for sent in sentences) / sentence\n",
    "    max_sentence_length = max(len(sent) for sent in sentences)\n",
    "    min_sentence_length = min(len(sent) for sent in sentences)\n",
    "    std_sentence_length = (sum((len(sent) - avg_sentence_length)**2 for sent in sentences) / sentence)**0.5\n",
    "    \n",
    "    # 10 Tree Depth\n",
    "    average_tree_depth = average_dependency_tree_depth(doc)\n",
    "    prob_word = [count/total_tokens for word, count in word_counts.items()]\n",
    "    results = {\n",
    "        \"nsubj\": 0,\n",
    "        \"amod\": 0,\n",
    "        \"advmod\": 0,\n",
    "        \"xcomp\": 0,\n",
    "        \"acomp\": 0,\n",
    "        \"past\": 0,\n",
    "        \"present\": 0\n",
    "    }\n",
    "    \n",
    "    summary_punc = 0\n",
    "    for token in doc:\n",
    "        if \"VERB\" == token.pos_:\n",
    "            if \"VBD\" == token.tag_ or \"VBN\" == token.tag_:\n",
    "                results[\"past\"] += 1\n",
    "            elif token.tag_ in {\"VBG\", \"VBP\", \"VBZ\"}:\n",
    "                results[\"present\"] += 1\n",
    "        # Check if the token's dependency is one of the desired dependencies\n",
    "        if token.dep_ in results:\n",
    "            results[token.dep_] += 1\n",
    "            \n",
    "        if token.is_punct:\n",
    "            summary_punc += 0\n",
    "    \n",
    "    # Unigram similarity\n",
    "    summary_set = set(tokens) if length > 0 else set()\n",
    "    context_set = set(context_tokens) if len(context_tokens) > 0 else set()\n",
    "    intersection = len(context_set.intersection(summary_set))\n",
    "    difference = len(context_set.difference(summary_set))\n",
    "    union = len(context_set.union(summary_set))\n",
    "    precision = float(intersection /unique_words) if unique_words > 0 else 0.0\n",
    "    recall = float(intersection / len(context_set)) if len(context_set) > 0 else 0.0\n",
    "    jaccard_similarity = float(intersection/union) if union > 0 else 0.0\n",
    "    overlap_score = intersection/float(min(len(context_set), len(summary_set)) + 1e-11)\n",
    "    f1_score = float(2 * ((precision * recall)/(precision + recall + 1e-11)))\n",
    "    \n",
    "    \n",
    "    # Bigram Similarity\n",
    "    answer_bigrams = set(list(ngrams(tokens, 2))) if length > 1 else set()\n",
    "    context_bigrams = set(list(ngrams(context_tokens, 2))) if len(context_tokens) > 1 else set()\n",
    "    intersection_bigram = len(answer_bigrams.intersection(context_bigrams))\n",
    "    union_bigram = len(answer_bigrams.union(context_bigrams))\n",
    "    precision_bigram = intersection_bigram /len(answer_bigrams) if len(answer_bigrams) > 0 else 0.0\n",
    "    recall_bigram = intersection_bigram / len(context_bigrams) if len(context_bigrams) > 0 else 0.0\n",
    "    jaccard_bigram = intersection_bigram/union_bigram if union_bigram > 0 else 0.0\n",
    "    bigram_overlap = np.sqrt(intersection_bigram/float(min(len(context_bigrams), len(answer_bigrams)) + 1e-11))\n",
    "    f1_bigram = 2 * ((precision_bigram * recall_bigram)/(precision_bigram + recall_bigram + 1e-11))\n",
    "    \n",
    "    # Trigram Similarity\n",
    "    answer_trigrams = set(list(ngrams(tokens, 3))) if length > 1 else set()\n",
    "    context_trigrams = set(list(ngrams(context_tokens, 3))) if len(context_tokens) > 1 else set()\n",
    "    intersection_trigram = len(answer_trigrams.intersection(context_trigrams))\n",
    "    union_trigram = len(answer_trigrams.union(context_trigrams))\n",
    "    precision_trigram = intersection_trigram / len(answer_trigrams) if len(answer_trigrams) > 0 else 0.0\n",
    "    recall_trigram = intersection_trigram / len(context_trigrams) if len(context_trigrams) > 0 else 0.0\n",
    "    jaccard_trigram = intersection_trigram/union_trigram if union_trigram > 0 else 0.0\n",
    "    trigram_overlap = intersection_trigram/float(min(len(context_trigrams), len(answer_trigrams)) + 1e-11)    \n",
    "    f1_trigram = 2 * ((precision_trigram * recall_trigram)/(precision_trigram + recall_trigram + 1e-11))\n",
    "    \n",
    "    # Readability\n",
    "    \n",
    "    num_syllables = np.log2(textstat.syllable_count(row['text']))\n",
    "    flesch_reading_ease = np.square(textstat.flesch_reading_ease(row['text']))/100\n",
    "    flesh = textstat.flesch_kincaid_grade(row['text'])\n",
    "    flesch_kincaid = np.log2(flesh if flesh > 0 else 1e-10)\n",
    "    \n",
    "    # Automated Reading Index\n",
    "    ari = textstat.automated_readability_index(row['text'])\n",
    "    summary_ari = np.log2(ari if ari > 0 else 1e-10)\n",
    "    \n",
    "    # Coleman-Liau Index Readability\n",
    "    # Where: L is the average number of letters per 100 words, S is the average number of sentences per 100 words\n",
    "    coleman_index = textstat.coleman_liau_index(row['text'])\n",
    "    dale_chall = textstat.dale_chall_readability_score(row['text'])\n",
    "    \n",
    "    # Mispelt\n",
    "    mis_tokens = [token for token in checker.unknown(tokens) if token.isalpha()]\n",
    "    mispell_ratio = len(mis_tokens)/total_tokens\n",
    "    mispell_ratio = np.log2(mispell_ratio if mispell_ratio > 0 else 1e-10)\n",
    "    quotes = len(re.findall(r'\"(.*?)\"|\\'(.*?)\\'|“(.*?)”|‘(.*?)’|«(.*?)»|‹(.*?)›', row['text']))\n",
    "    \n",
    "    source_vector = context.vector\n",
    "    answer_vector = doc.vector\n",
    "    \n",
    "    embedding_similarity, euclidean, pearson = compute_similarity_score(source_vector, answer_vector)\n",
    "    \n",
    "    \n",
    "    # Organizing features in a dictionary\n",
    "    features = {\n",
    "        'length': np.log2(length),\n",
    "        'num_chars': np.log2(textstat.char_count(row['text'])),\n",
    "        'lexicon_count': np.log2(textstat.lexicon_count(row['text'])),\n",
    "        'word_per_sentence': np.log2(textstat.words_per_sentence(row['text'])),\n",
    "        'avg_syllables_per_word': textstat.avg_syllables_per_word(row['text']),\n",
    "        \"mispelt_tokens\": len(mis_tokens),\n",
    "        \"capital_error\": capital_error,\n",
    "        \"mispell_ratio\": mispell_ratio,\n",
    "        \"quotes\": quotes,\n",
    "        \"intersection_bigram\": np.log2(intersection_bigram + 1e-11),\n",
    "        \"union_bigram\": np.sqrt(union_bigram),\n",
    "        \"jaccard_bigram\": np.abs(np.log2(jaccard_bigram + 1e-11)),\n",
    "        'recall_bigram': np.abs(np.log2(recall_bigram + 1e-11)),\n",
    "        \"precision_bigram\": np.sqrt(precision_bigram),\n",
    "        \"f1_bigram\": np.abs(np.log2(f1_bigram + 1e-11)),\n",
    "        'bigram_overlap': bigram_overlap,\n",
    "        'sentence': np.log2(sentence + 1e-11),\n",
    "        'avg_sentence_length': avg_sentence_length, \n",
    "        'max_sentence_length': max_sentence_length,\n",
    "        'min_sentence_length':min_sentence_length,\n",
    "        \"std_sentence_length\": std_sentence_length,\n",
    "        \"avg_sentence\": avg_sentence,\n",
    "        'avg_unique_sentence':avg_unique_sentence,\n",
    "        \"context_avg_word_len\": context_avg_word_len,\n",
    "        \"error\": error,\n",
    "        'error_ratio': error_ratio,\n",
    "        'unique_words': unique_words,\n",
    "        'num_entities': num_entities,\n",
    "        \"context_num_entities\": context_num_entities,\n",
    "        'coverage_score': coverage_score,\n",
    "        'num_overlap_entities': num_overlap_entities,\n",
    "        'avg_word_len': avg_word_len,\n",
    "        'intersection_trigram': intersection_trigram,\n",
    "        'union_trigram': union_trigram,\n",
    "        'recall_trigram': recall_trigram,\n",
    "        'precision_trigram': precision_trigram,\n",
    "        'jaccard_trigram': jaccard_trigram,\n",
    "        'trigram_overlap': trigram_overlap,\n",
    "        'f1_trigram': f1_trigram,\n",
    "        \"stops\": stops,\n",
    "        \"num_nouns\": num_nouns,\n",
    "        \"num_verbs\": num_verbs,\n",
    "        \"num_adverbs\": num_adverbs,\n",
    "        \"context_nouns\": context_nouns,\n",
    "        \"context_stops\": context_stops, \n",
    "        'context_verbs': context_verbs,\n",
    "        'context_adverbs': context_adverbs,\n",
    "        \"num_numerical_entities\": num_numerical_entities,\n",
    "        \"sentiment_polarity\": sentiment_polarity,\n",
    "        'context_polarity': context_polarity, \n",
    "        \"nsubj\": results['nsubj'],\n",
    "        \"amod\": results['amod'],\n",
    "        \"advmod\": results['advmod'],\n",
    "        \"xcomp\": results['xcomp'],\n",
    "        \"acomp\": results['acomp'],\n",
    "        \"past\": results[\"past\"],\n",
    "        \"present\": results[\"present\"],\n",
    "        \"average_dependency_tree_depth\": average_tree_depth,\n",
    "        \"TTR\": unique_words / (total_tokens + 1e-8),\n",
    "        \"RTTR\": unique_words / (math.sqrt(total_tokens) + 1e-8),\n",
    "        \"CTTR\": unique_words / (math.sqrt(total_tokens / 2) + 1e-8),\n",
    "        # MATTR would require a window-based approach and is thus more involved\n",
    "        \"Herdan's C\": math.log(unique_words) / (math.log(total_tokens) + 1e-8),\n",
    "        \"Dugast's U\": math.log(total_tokens)**2 / ((math.log(total_tokens) - math.log(unique_words)) + 1e-8),\n",
    "        \"Honoré's H\": 100 * math.log(total_tokens) / (1 - once/(unique_words + 1e-8)),\n",
    "        \"Entropy\": -sum(p * math.log(p) for p in prob_word),\n",
    "        \"Sichel’s S\": twice,\n",
    "        'named_entity_ratio': named_entity_ratio,\n",
    "        'context_entity_ratio': context_entity_ratio,\n",
    "        'num_syllables': num_syllables,\n",
    "        'flesch_reading_ease': flesch_reading_ease,\n",
    "        'flesch_kincaid': flesch_kincaid,\n",
    "        'summary_ari':summary_ari,\n",
    "        'coleman_index': coleman_index,\n",
    "        'dale_chall': dale_chall,\n",
    "        \"Simpson’s D\": sum((count/total_tokens)**2 for count in word_counts.values()),\n",
    "        'intersection': intersection,\n",
    "        \"subjectivity\": subjectivity,\n",
    "        \"context_subjectivity\": context_subjectivity,\n",
    "        'difference': difference,\n",
    "        'union': union,\n",
    "        'overlap_score': overlap_score,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1_score': f1_score,\n",
    "        'jaccard_similarity': jaccard_similarity,\n",
    "        'embedding_similarity': embedding_similarity,\n",
    "        'euclidean': euclidean, \n",
    "        'pearson': pearson,\n",
    "        'summary_punc': summary_punc,\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def compute_similarity_score(source_vector, answer_vector):\n",
    "    embedding_similarity = cosine_similarity([source_vector], [answer_vector])[0][0]\n",
    "    euclidean = euclidean_distances([source_vector], [answer_vector])[0][0]\n",
    "    pearson = np.corrcoef(source_vector.ravel(), answer_vector.ravel())[0, 1]\n",
    "    \n",
    "    return embedding_similarity, euclidean, pearson\n",
    "\n",
    "def compute_mean_statistics(embedding):\n",
    "    negatives_count = np.sum(embedding < 0, axis=1)\n",
    "    negatives_count_ratio = negatives_count/768\n",
    "    pos = 768 - negatives_count\n",
    "    pos_ratio = pos/768\n",
    "    neg_pos_ratio = negatives_count/pos\n",
    "    embed_sum = np.square(np.sum(embedding, axis=1))/100\n",
    "    embed_mean = np.square(np.mean(embedding, axis=1)) * 100\n",
    "    embed_var = np.var(embedding, axis=1)\n",
    "    embed_std = np.std(embedding, axis=1)\n",
    "    quantile_1 = np.square(np.quantile(embedding,0.25,axis=1))\n",
    "    quantile_2 = np.quantile(embedding,0.5,axis=1)\n",
    "    quantile_3 = np.square(np.quantile(embedding,0.75,axis=1))\n",
    "    quantile_4 = np.square(np.quantile(embedding,1,axis=1))/10\n",
    "    embed_range = np.log2(np.max(embedding,axis=1) - np.min(embedding,axis=1))\n",
    "    kurtosis_bag = kurtosis(embedding, axis=1)\n",
    "    l2_norm = np.linalg.norm(embedding, axis=1)\n",
    "    l1_norm = np.linalg.norm(embedding, ord=1, axis=1)\n",
    "    output =  np.asarray([embed_range,embed_sum, embed_mean, embed_var, embed_std,\n",
    "                          np.log2(pos + 1e-11), pos_ratio, negatives_count/100,negatives_count_ratio,\n",
    "                          np.sqrt(neg_pos_ratio ** 10), quantile_1,quantile_2,quantile_3,\n",
    "                          quantile_4,np.log2(np.log2(kurtosis_bag + 1e-11)) ** 2,l2_norm,l1_norm],dtype=np.float32).T\n",
    "    return output\n",
    "\n",
    "\n",
    "def compute_statistical_measures(embedding):\n",
    "    negatives_count = np.sum(embedding < 0, axis=1)\n",
    "    negatives_count_ratio = negatives_count/768\n",
    "    pos = 768 - negatives_count\n",
    "    pos_ratio = pos/768\n",
    "    neg_pos_ratio = negatives_count/pos\n",
    "    embed_sum = np.sum(embedding, axis=1)\n",
    "    embed_mean = np.mean(embedding, axis=1)\n",
    "    embed_var = np.var(embedding, axis=1)\n",
    "    embed_std = np.std(embedding, axis=1)\n",
    "    quantile_1 = np.quantile(embedding,0.25,axis=1)\n",
    "    quantile_2 = np.quantile(embedding,0.5,axis=1)\n",
    "    quantile_3 = np.quantile(embedding,0.75,axis=1)\n",
    "    quantile_4 = np.quantile(embedding,1,axis=1)\n",
    "    embed_range = np.max(embedding,axis=1) - np.min(embedding,axis=1)\n",
    "    p2p = np.ptp(embedding, axis=1)\n",
    "    skewed_bag = skew(embedding, axis=1)\n",
    "    kurtosis_bag = kurtosis(embedding, axis=1)\n",
    "    l2_norm = np.linalg.norm(embedding, axis=1)\n",
    "    l1_norm = np.linalg.norm(embedding, ord=1, axis=1)\n",
    "    output =  np.asarray([embed_range,embed_sum, embed_mean, embed_var, embed_std,\n",
    "                          pos, pos_ratio, negatives_count,negatives_count_ratio,\n",
    "                          neg_pos_ratio, quantile_1,quantile_2, quantile_3,\n",
    "                          quantile_4,p2p,skewed_bag,kurtosis_bag,l2_norm,l1_norm],dtype=np.float32).T\n",
    "    return output\n",
    "\n",
    "\n",
    "def compute_tensor(texts, max_len=128):\n",
    "    outputs = tokenizer(texts,  max_length=max_len,padding='max_length',\n",
    "                    truncation=True,return_tensors='tf')\n",
    "    tensor = model(**outputs)['last_hidden_state']\n",
    "    return tensor\n",
    "def compute_scores(batch_texts,max_len):\n",
    "    tensor = compute_tensor(batch_texts, max_len)\n",
    "    embed_mean = tf.reduce_mean(tensor, axis=1).cpu().numpy()\n",
    "    embed_max = tf.reduce_max(tensor, axis=1).cpu().numpy()\n",
    "    embed_first = tensor[:,0,:].cpu().numpy()\n",
    "    \n",
    "    features_batch = np.hstack((embed_mean, embed_max, embed_first))\n",
    "    return features_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92111a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:02:13.014960Z",
     "iopub.status.busy": "2023-10-09T10:02:13.014587Z",
     "iopub.status.idle": "2023-10-09T10:02:13.025170Z",
     "shell.execute_reply": "2023-10-09T10:02:13.024058Z"
    },
    "papermill": {
     "duration": 0.019324,
     "end_time": "2023-10-09T10:02:13.027147",
     "exception": false,
     "start_time": "2023-10-09T10:02:13.007823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(summary_df, prompt_df, BATCH_SIZE=8, max_len=256):\n",
    "    train_df = summary_df.merge(right=prompt_df, how='inner', on='prompt_id')\n",
    "\n",
    "    print('processing text embeddings......')\n",
    "    docs = list(nlp.pipe(train_df['text']))\n",
    "    context_docs = list(nlp.pipe(train_df['prompt_text']))\n",
    "    \n",
    "    # processing lemmas\n",
    "    print('extracting features.....')\n",
    "    drop_cols = [\n",
    "                \"mispelt_tokens\",\"mispell_ratio\",'error_ratio',\n",
    "                'context_nouns','context_entity_ratio',\n",
    "                'context_verbs', 'context_adverbs','context_subjectivity'\n",
    "    ]\n",
    "    data_cols = ['context_subjectivity', 'difference', 'recall',\n",
    "        'union','union_trigram', 'recall_trigram',\n",
    "        'union_bigram', 'recall_bigram',\n",
    "        'context_nouns','context_entity_ratio',\n",
    "        'context_verbs', 'context_adverbs']\n",
    "    \n",
    "    data = pd.DataFrame(train_df.apply(extract_features, args=(docs, context_docs), axis=1).tolist())\n",
    "    content_data = data.drop(drop_cols, axis=1)\n",
    "    data = data.drop(data_cols, axis=1)\n",
    "    \n",
    "    print('processing features.....')\n",
    "    # Process other columns\n",
    "    scores = []\n",
    "    num_samples = len(train_df)\n",
    "    for start_idx in tqdm(range(0, num_samples, BATCH_SIZE), desc=\"processing feature extraction\"):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, num_samples)\n",
    "        batch_texts = train_df.iloc[start_idx:end_idx]['text'].apply(speller).tolist()\n",
    "\n",
    "        with tf.device('/GPU:0'):\n",
    "            scores_batch = compute_scores(batch_texts, max_len=max_len)\n",
    "            scores.extend(scores_batch)\n",
    "            \n",
    "            K.clear_session()\n",
    "\n",
    "    bert_features = np.asarray(scores, dtype=np.float32)\n",
    "    stats_mean = compute_mean_statistics(bert_features[:,:768])\n",
    "    stats_max = compute_statistical_measures(bert_features[:,768:1536])\n",
    "    stats_first = compute_statistical_measures(bert_features[:,1536:])\n",
    "\n",
    "    content_bag = np.hstack((bert_features[:,:768],stats_mean,stats_max,stats_first,\n",
    "                             content_data.values, train_df[['content']].values))\n",
    "    wording_bag = np.hstack((bert_features[:,:768],stats_mean,stats_max,stats_first,\n",
    "                             data.values, train_df[['wording']].values))\n",
    "    \n",
    "    print('collecting outputs.........')\n",
    "    student_ids = train_df['student_id'].values\n",
    "\n",
    "    return content_bag, wording_bag, student_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d28815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T10:02:13.040224Z",
     "iopub.status.busy": "2023-10-09T10:02:13.039879Z",
     "iopub.status.idle": "2023-10-09T12:24:09.761535Z",
     "shell.execute_reply": "2023-10-09T12:24:09.758350Z"
    },
    "papermill": {
     "duration": 8516.731158,
     "end_time": "2023-10-09T12:24:09.764235",
     "exception": false,
     "start_time": "2023-10-09T10:02:13.033077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing text embeddings......\n",
      "extracting features.....\n",
      "processing features.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing feature extraction: 100%|██████████| 896/896 [2:06:46<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting outputs.........\n",
      "Preprocessed function executed in: 8516.71 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "content_bag, wording_bag, student_ids = preprocess_data(summary_df,prompt_df,BATCH_SIZE=8,\n",
    "                                                        max_len=256)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Preprocessed function executed in: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88eabd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:24:09.871030Z",
     "iopub.status.busy": "2023-10-09T12:24:09.870505Z",
     "iopub.status.idle": "2023-10-09T12:24:09.880678Z",
     "shell.execute_reply": "2023-10-09T12:24:09.879714Z"
    },
    "papermill": {
     "duration": 0.067574,
     "end_time": "2023-10-09T12:24:09.882497",
     "exception": false,
     "start_time": "2023-10-09T12:24:09.814923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(df[:,:-1] ,df[:,-1],test_size=0.1,shuffle=True,random_state=11)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6ec725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:24:09.985861Z",
     "iopub.status.busy": "2023-10-09T12:24:09.985465Z",
     "iopub.status.idle": "2023-10-09T12:24:09.990928Z",
     "shell.execute_reply": "2023-10-09T12:24:09.989900Z"
    },
    "papermill": {
     "duration": 0.059576,
     "end_time": "2023-10-09T12:24:09.992673",
     "exception": false,
     "start_time": "2023-10-09T12:24:09.933097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mcrmse(y_true, y_pred):\n",
    "    return np.mean(np.sqrt(np.mean((y_true - y_pred)**2, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbee86a",
   "metadata": {
    "papermill": {
     "duration": 0.049995,
     "end_time": "2023-10-09T12:24:10.093712",
     "exception": false,
     "start_time": "2023-10-09T12:24:10.043717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82e93ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:24:10.199084Z",
     "iopub.status.busy": "2023-10-09T12:24:10.198729Z",
     "iopub.status.idle": "2023-10-09T12:24:10.232763Z",
     "shell.execute_reply": "2023-10-09T12:24:10.231659Z"
    },
    "papermill": {
     "duration": 0.088427,
     "end_time": "2023-10-09T12:24:10.235109",
     "exception": false,
     "start_time": "2023-10-09T12:24:10.146682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "def train_model(df):\n",
    "    X_train,X_test,y_train,y_test = split_data(df)\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 600,\n",
    "        'max_depth': 11,\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse'\n",
    "    }\n",
    "\n",
    "    best_models = []\n",
    "\n",
    "    score = []\n",
    "    kfold = KFold(n_splits=20, shuffle=True, random_state=64)\n",
    "    for train_idx, test_idx in tqdm(kfold.split(X_train, y_train), desc='training model'):\n",
    "        X, y = X_train[train_idx], y_train[train_idx]\n",
    "        test,test_y = X_train[test_idx], y_train[test_idx]\n",
    "        pipeline = make_pipeline(\n",
    "            MinMaxScaler(feature_range=(-10,10)),\n",
    "            lgb.LGBMRegressor(**best_params, random_state=64)\n",
    "        )\n",
    "        \n",
    "        pipeline.fit(X, y)\n",
    "        score.append(np.sqrt(mean_squared_error(test_y,pipeline.predict(test))))\n",
    "        best_models.append(pipeline)\n",
    "\n",
    "    print(f'Train Mean Score: {np.mean(score):.4f}')\n",
    "    \n",
    "    best_scores = []\n",
    "    for i in range(len(best_models)):\n",
    "        best_model = best_models[i]\n",
    "        y_preds = best_model.predict(X_test)\n",
    "        best_scores.append(np.sqrt(mean_squared_error(y_test,y_preds)))\n",
    "    print(f'Evaluation Mean Score: {np.mean(best_scores):.4f}')\n",
    "    \n",
    "    best_model_idx = np.argmin(best_scores)\n",
    "    best_model = best_models[best_model_idx]\n",
    "    \n",
    "    y_preds = best_model.predict(X_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test,y_preds))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time \n",
    "    print(f\"Preprocessed function executed in: {elapsed_time:.2f} seconds\")\n",
    "    print(f'Best Model Score: {score:.4f}')\n",
    "    \n",
    "    return best_model, y_test, y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adf19f",
   "metadata": {
    "papermill": {
     "duration": 0.05005,
     "end_time": "2023-10-09T12:24:10.336051",
     "exception": false,
     "start_time": "2023-10-09T12:24:10.286001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "73 -77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a9252b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:24:10.439252Z",
     "iopub.status.busy": "2023-10-09T12:24:10.438459Z",
     "iopub.status.idle": "2023-10-09T12:35:37.055394Z",
     "shell.execute_reply": "2023-10-09T12:35:37.054311Z"
    },
    "papermill": {
     "duration": 686.671149,
     "end_time": "2023-10-09T12:35:37.057491",
     "exception": false,
     "start_time": "2023-10-09T12:24:10.386342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model: 20it [11:25, 34.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Score: 0.4038\n",
      "Evaluation Mean Score: 0.4039\n",
      "Preprocessed function executed in: 686.57 seconds\n",
      "Best Model Score: 0.4006\n"
     ]
    }
   ],
   "source": [
    "content_model, content_test, content_preds = train_model(content_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0fc3f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:35:37.166093Z",
     "iopub.status.busy": "2023-10-09T12:35:37.165536Z",
     "iopub.status.idle": "2023-10-09T12:46:57.014391Z",
     "shell.execute_reply": "2023-10-09T12:46:57.013069Z"
    },
    "papermill": {
     "duration": 679.904539,
     "end_time": "2023-10-09T12:46:57.016386",
     "exception": false,
     "start_time": "2023-10-09T12:35:37.111847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model: 20it [11:19, 33.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Score: 0.5226\n",
      "Evaluation Mean Score: 0.5125\n",
      "Preprocessed function executed in: 679.80 seconds\n",
      "Best Model Score: 0.5084\n"
     ]
    }
   ],
   "source": [
    "wording_model, wording_test, wording_preds  = train_model(wording_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67801aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:46:57.127287Z",
     "iopub.status.busy": "2023-10-09T12:46:57.126908Z",
     "iopub.status.idle": "2023-10-09T12:46:57.132868Z",
     "shell.execute_reply": "2023-10-09T12:46:57.131882Z"
    },
    "papermill": {
     "duration": 0.063861,
     "end_time": "2023-10-09T12:46:57.134842",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.070981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = np.hstack((content_test.reshape((-1,1)), wording_test.reshape((-1,1))))\n",
    "preds = np.hstack((content_preds.reshape((-1,1)), wording_preds.reshape((-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0e3274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:46:57.244877Z",
     "iopub.status.busy": "2023-10-09T12:46:57.243916Z",
     "iopub.status.idle": "2023-10-09T12:46:57.256055Z",
     "shell.execute_reply": "2023-10-09T12:46:57.254843Z"
    },
    "papermill": {
     "duration": 0.068955,
     "end_time": "2023-10-09T12:46:57.258121",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.189166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4545213883583197"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcrmse(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caab1f",
   "metadata": {
    "papermill": {
     "duration": 0.053206,
     "end_time": "2023-10-09T12:46:57.368041",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.314835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<!-- 0.3911, 0.5052\n",
    "0.4485718981897328 -->\n",
    "\n",
    "<!-- 0.3977, 0.5024, 0.4500634205747211 -->\n",
    "\n",
    "Best Model Score: 0.3972\n",
    "\n",
    "\n",
    "Best Model Score: 0.5079\n",
    "\n",
    "0.45256979534083225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db1175a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:46:57.478114Z",
     "iopub.status.busy": "2023-10-09T12:46:57.477765Z",
     "iopub.status.idle": "2023-10-09T12:46:57.481527Z",
     "shell.execute_reply": "2023-10-09T12:46:57.480848Z"
    },
    "papermill": {
     "duration": 0.060795,
     "end_time": "2023-10-09T12:46:57.483158",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.422363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from joblib import dump\n",
    "\n",
    "# # Save the pipeline to a file\n",
    "# dump(content_model, 'content_model.joblib')\n",
    "# dump(wording_model, 'wording_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed24e65",
   "metadata": {
    "papermill": {
     "duration": 0.053561,
     "end_time": "2023-10-09T12:46:57.591205",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.537644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocessing for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ffee8bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:46:57.702863Z",
     "iopub.status.busy": "2023-10-09T12:46:57.701888Z",
     "iopub.status.idle": "2023-10-09T12:46:57.722125Z",
     "shell.execute_reply": "2023-10-09T12:46:57.721122Z"
    },
    "papermill": {
     "duration": 0.078661,
     "end_time": "2023-10-09T12:46:57.724534",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.645873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def preprocess_data(summary_df, prompt_df, BATCH_SIZE=8, max_len=128):\n",
    "    train_df = summary_df.merge(right=prompt_df, how='inner', on='prompt_id')\n",
    "\n",
    "    print('processing text embeddings......')\n",
    "    docs = list(nlp.pipe(train_df['text']))\n",
    "    context_docs = list(nlp.pipe(train_df['prompt_text']))\n",
    "    \n",
    "    # processing lemmas\n",
    "    print('extracting features.....')\n",
    "    drop_cols = [\n",
    "                \"mispelt_tokens\",\"mispell_ratio\",'error_ratio',\n",
    "                'context_nouns','context_entity_ratio',\n",
    "                'context_verbs', 'context_adverbs','context_subjectivity'\n",
    "    ]\n",
    "    data_cols = ['context_subjectivity', 'difference', 'recall',\n",
    "        'union','union_trigram', 'recall_trigram',\n",
    "        'union_bigram', 'recall_bigram',\n",
    "        'context_nouns','context_entity_ratio',\n",
    "        'context_verbs', 'context_adverbs']\n",
    "    \n",
    "    data = pd.DataFrame(train_df.apply(extract_features, args=(docs, context_docs), axis=1).tolist())\n",
    "    content_data = data.drop(drop_cols, axis=1)\n",
    "    data = data.drop(data_cols, axis=1)\n",
    "    \n",
    "    print('processing features.....')\n",
    "    # Process other columns\n",
    "    scores = []\n",
    "    num_samples = len(train_df)\n",
    "    for start_idx in tqdm(range(0, num_samples, BATCH_SIZE), desc=\"processing feature extraction\"):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, num_samples)\n",
    "        batch_texts = train_df.iloc[start_idx:end_idx]['text'].apply(speller).tolist()\n",
    "\n",
    "        with tf.device('/GPU:0'):\n",
    "            scores_batch = compute_scores(batch_texts,max_len)\n",
    "            scores.extend(scores_batch)\n",
    "            \n",
    "            K.clear_session()\n",
    "\n",
    "    bert_features = np.asarray(scores, dtype=np.float32)\n",
    "    stats_mean = compute_mean_statistics(bert_features[:,:768])\n",
    "    stats_max = compute_statistical_measures(bert_features[:,768:1536])\n",
    "    stats_first = compute_statistical_measures(bert_features[:,1536:])\n",
    "\n",
    "    content_bag = np.hstack((bert_features[:,:768],stats_mean,stats_max,stats_first,\n",
    "                             content_data.values))\n",
    "    wording_bag = np.hstack((bert_features[:,:768],stats_mean,stats_max,stats_first,\n",
    "                             data.values))\n",
    "    \n",
    "    print('collecting outputs.........')\n",
    "    student_ids = train_df['student_id'].values\n",
    "\n",
    "    return content_bag, wording_bag, student_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db81f215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:46:57.836812Z",
     "iopub.status.busy": "2023-10-09T12:46:57.836164Z",
     "iopub.status.idle": "2023-10-09T12:47:01.610921Z",
     "shell.execute_reply": "2023-10-09T12:47:01.609635Z"
    },
    "papermill": {
     "duration": 3.833483,
     "end_time": "2023-10-09T12:47:01.613034",
     "exception": false,
     "start_time": "2023-10-09T12:46:57.779551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing text embeddings......\n",
      "extracting features.....\n",
      "processing features.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing feature extraction: 100%|██████████| 1/1 [00:03<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting outputs.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "content, wording,ids = preprocess_data(test_summary, test_prompts,BATCH_SIZE=8,\n",
    "                                       max_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5ecc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:47:01.730233Z",
     "iopub.status.busy": "2023-10-09T12:47:01.729839Z",
     "iopub.status.idle": "2023-10-09T12:47:01.738161Z",
     "shell.execute_reply": "2023-10-09T12:47:01.736970Z"
    },
    "papermill": {
     "duration": 0.070956,
     "end_time": "2023-10-09T12:47:01.740650",
     "exception": false,
     "start_time": "2023-10-09T12:47:01.669694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cont_preds = content_model.predict(content).reshape((-1,1))\n",
    "word_preds = wording_model.predict(wording).reshape((-1,1))\n",
    "y_preds = np.hstack((cont_preds, word_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235fba5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:47:01.859188Z",
     "iopub.status.busy": "2023-10-09T12:47:01.858739Z",
     "iopub.status.idle": "2023-10-09T12:47:01.867563Z",
     "shell.execute_reply": "2023-10-09T12:47:01.866505Z"
    },
    "papermill": {
     "duration": 0.068596,
     "end_time": "2023-10-09T12:47:01.869631",
     "exception": false,
     "start_time": "2023-10-09T12:47:01.801035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(y_preds,columns=['content','wording'],index=ids).reset_index()\n",
    "df_test = df_test.rename({'index':'student_id'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d008e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:47:01.982360Z",
     "iopub.status.busy": "2023-10-09T12:47:01.982013Z",
     "iopub.status.idle": "2023-10-09T12:47:02.002500Z",
     "shell.execute_reply": "2023-10-09T12:47:02.001281Z"
    },
    "papermill": {
     "duration": 0.078937,
     "end_time": "2023-10-09T12:47:02.004900",
     "exception": false,
     "start_time": "2023-10-09T12:47:01.925963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_valid_float(x):\n",
    "    return isinstance(x, float) and x == x  # This checks that x is not NaN since NaN != NaN in Python.\n",
    "\n",
    "cols_to_check = ['wording', 'content']\n",
    "df_test[cols_to_check] = df_test[cols_to_check].applymap(lambda x: x if is_valid_float(x) else 0.0)\n",
    "\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54379a8c",
   "metadata": {
    "papermill": {
     "duration": 0.054289,
     "end_time": "2023-10-09T12:47:02.113184",
     "exception": false,
     "start_time": "2023-10-09T12:47:02.058895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9945.342874,
   "end_time": "2023-10-09T12:47:05.102802",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-09T10:01:19.759928",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
